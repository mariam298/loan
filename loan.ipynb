{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ccJNs03-6cjP"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the train and test datasets\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n"
      ],
      "metadata": {
        "id": "iGO4ogHM-7Eb"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploratory Data Analysis\n",
        "print(train_data.head())  # Check the first few rows of the train dataset\n",
        "print(train_data.describe())  # Summary statistics of the train dataset\n",
        "print(train_data.info())  # Information about the train dataset\n",
        "print(train_data['Loan_Status'].value_counts())  # Distribution of the target variable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEiDajaJ--6u",
        "outputId": "38f1d903-9849-40ef-ec3d-6593bdd436d0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
            "0  LP001002   Male      No          0      Graduate            No   \n",
            "1  LP001003   Male     Yes          1      Graduate            No   \n",
            "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
            "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
            "4  LP001008   Male      No          0      Graduate            No   \n",
            "\n",
            "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
            "0             5849                0.0         NaN             360.0   \n",
            "1             4583             1508.0       128.0             360.0   \n",
            "2             3000                0.0        66.0             360.0   \n",
            "3             2583             2358.0       120.0             360.0   \n",
            "4             6000                0.0       141.0             360.0   \n",
            "\n",
            "   Credit_History Property_Area Loan_Status  \n",
            "0             1.0         Urban           Y  \n",
            "1             1.0         Rural           N  \n",
            "2             1.0         Urban           Y  \n",
            "3             1.0         Urban           Y  \n",
            "4             1.0         Urban           Y  \n",
            "       ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
            "count       614.000000         614.000000  592.000000         600.00000   \n",
            "mean       5403.459283        1621.245798  146.412162         342.00000   \n",
            "std        6109.041673        2926.248369   85.587325          65.12041   \n",
            "min         150.000000           0.000000    9.000000          12.00000   \n",
            "25%        2877.500000           0.000000  100.000000         360.00000   \n",
            "50%        3812.500000        1188.500000  128.000000         360.00000   \n",
            "75%        5795.000000        2297.250000  168.000000         360.00000   \n",
            "max       81000.000000       41667.000000  700.000000         480.00000   \n",
            "\n",
            "       Credit_History  \n",
            "count      564.000000  \n",
            "mean         0.842199  \n",
            "std          0.364878  \n",
            "min          0.000000  \n",
            "25%          1.000000  \n",
            "50%          1.000000  \n",
            "75%          1.000000  \n",
            "max          1.000000  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 614 entries, 0 to 613\n",
            "Data columns (total 13 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   Loan_ID            614 non-null    object \n",
            " 1   Gender             601 non-null    object \n",
            " 2   Married            611 non-null    object \n",
            " 3   Dependents         599 non-null    object \n",
            " 4   Education          614 non-null    object \n",
            " 5   Self_Employed      582 non-null    object \n",
            " 6   ApplicantIncome    614 non-null    int64  \n",
            " 7   CoapplicantIncome  614 non-null    float64\n",
            " 8   LoanAmount         592 non-null    float64\n",
            " 9   Loan_Amount_Term   600 non-null    float64\n",
            " 10  Credit_History     564 non-null    float64\n",
            " 11  Property_Area      614 non-null    object \n",
            " 12  Loan_Status        614 non-null    object \n",
            "dtypes: float64(4), int64(1), object(8)\n",
            "memory usage: 62.5+ KB\n",
            "None\n",
            "Y    422\n",
            "N    192\n",
            "Name: Loan_Status, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the total income by combining applicant and coapplicant incomes\n",
        "train_data['TotalIncome'] = train_data['ApplicantIncome'] + train_data['CoapplicantIncome']\n",
        "test_data['TotalIncome'] = test_data['ApplicantIncome'] + test_data['CoapplicantIncome']\n",
        "\n",
        "# Perform log transformation on LoanAmount to reduce skewness\n",
        "train_data['LoanAmount_Log'] = np.log(train_data['LoanAmount'])\n",
        "test_data['LoanAmount_Log'] = np.log(test_data['LoanAmount'])"
      ],
      "metadata": {
        "id": "MYYK6mRe_CRd"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_data = pd.concat([train_data.drop('Loan_Status', axis=1), test_data])\n",
        "\n",
        "# Fill missing values with appropriate methods\n",
        "combined_data['Gender'].fillna(combined_data['Gender'].mode()[0], inplace=True)\n",
        "combined_data['Married'].fillna(combined_data['Married'].mode()[0], inplace=True)\n",
        "combined_data['Dependents'].fillna(combined_data['Dependents'].mode()[0], inplace=True)\n",
        "combined_data['Self_Employed'].fillna(combined_data['Self_Employed'].mode()[0], inplace=True)\n",
        "combined_data['LoanAmount'].fillna(combined_data['LoanAmount'].median(), inplace=True)\n",
        "combined_data['Loan_Amount_Term'].fillna(combined_data['Loan_Amount_Term'].mode()[0], inplace=True)\n",
        "combined_data['Credit_History'].fillna(combined_data['Credit_History'].mode()[0], inplace=True)"
      ],
      "metadata": {
        "id": "uavq1i51_KoJ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode categorical variables\n",
        "label_encoder = LabelEncoder()\n",
        "combined_data['Gender'] = label_encoder.fit_transform(combined_data['Gender'])\n",
        "combined_data['Married'] = label_encoder.fit_transform(combined_data['Married'])\n",
        "combined_data['Education'] = label_encoder.fit_transform(combined_data['Education'])\n",
        "combined_data['Self_Employed'] = label_encoder.fit_transform(combined_data['Self_Employed'])\n",
        "combined_data['Property_Area'] = label_encoder.fit_transform(combined_data['Property_Area'])"
      ],
      "metadata": {
        "id": "OlFhdyTj_P2n"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the combined dataset back into train and test datasets\n",
        "train_data = combined_data[:len(train_data)]\n",
        "test_data = combined_data[len(train_data):]"
      ],
      "metadata": {
        "id": "mNi6tJs5_VXd"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Feature scaling\n",
        "scaler = MinMaxScaler()\n"
      ],
      "metadata": {
        "id": "ZtTEf1Rb_aSc"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale numerical features in the train dataset\n",
        "train_data[['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']] = \\\n",
        "    scaler.fit_transform(train_data[['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZO1745eT_eOl",
        "outputId": "3355250f-2de6-4cae-af6a-5b97ddcb98da"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-3550cb239833>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_data[['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']] = \\\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale numerical features in the test dataset\n",
        "test_data[['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']] = \\\n",
        "    scaler.transform(test_data[['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGJnPrFF_hZn",
        "outputId": "06274f81-a57e-4f9d-ec47-850ba9b53ff4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-f2634418056b>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_data[['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']] = \\\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed',\n",
        "            'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term',\n",
        "            'Credit_History', 'Property_Area']\n",
        "target = 'Loan_Status'\n"
      ],
      "metadata": {
        "id": "OrBTjWwI_rSm"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_data[features]\n",
        "y = train_data[target]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "ZJm0Kh6I_xVV",
        "outputId": "abc6dd1a-9814-486d-ee39-a4369e3425f5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Loan_Status'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-abf27b8baccc>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Loan_Status'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCvKI67vAMZo",
        "outputId": "70566364-be48-4c64-d035-754b6174887a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Loan_ID', 'Gender', 'Married', 'Dependents', 'Education',\n",
            "       'Self_Employed', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',\n",
            "       'Loan_Amount_Term', 'Credit_History', 'Property_Area', 'TotalIncome',\n",
            "       'LoanAmount_Log'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwXn3t_iAenS",
        "outputId": "9e669d1d-3e98-41d2-f997-90a4e27f78c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Loan_ID', 'Gender', 'Married', 'Dependents', 'Education',\n",
            "       'Self_Employed', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',\n",
            "       'Loan_Amount_Term', 'Credit_History', 'Property_Area', 'TotalIncome',\n",
            "       'LoanAmount_Log'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('train.csv', delimiter=';')"
      ],
      "metadata": {
        "id": "s231v-zzBlk0"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyCMZ2L9Bqhi",
        "outputId": "c0203c80-067f-417e-d62d-9cc020d32192"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Loan_ID,Gender,Married,Dependents,Education,Self_Employed,ApplicantIncome,CoapplicantIncome,LoanAmount,Loan_Amount_Term,Credit_History,Property_Area,Loan_Status\n",
            "0    LP001002,Male,No,0,Graduate,No,5849,0,,360,1,U...                                                                                                              \n",
            "1    LP001003,Male,Yes,1,Graduate,No,4583,1508,128,...                                                                                                              \n",
            "2    LP001005,Male,Yes,0,Graduate,Yes,3000,0,66,360...                                                                                                              \n",
            "3    LP001006,Male,Yes,0,Not Graduate,No,2583,2358,...                                                                                                              \n",
            "4    LP001008,Male,No,0,Graduate,No,6000,0,141,360,...                                                                                                              \n",
            "..                                                 ...                                                                                                              \n",
            "609  LP002978,Female,No,0,Graduate,No,2900,0,71,360...                                                                                                              \n",
            "610  LP002979,Male,Yes,3+,Graduate,No,4106,0,40,180...                                                                                                              \n",
            "611  LP002983,Male,Yes,1,Graduate,No,8072,240,253,3...                                                                                                              \n",
            "612  LP002984,Male,Yes,2,Graduate,No,7583,0,187,360...                                                                                                              \n",
            "613  LP002990,Female,No,0,Graduate,Yes,4583,0,133,3...                                                                                                              \n",
            "\n",
            "[614 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load the train dataset\n",
        "train_data = pd.read_csv('train.csv')\n",
        "\n",
        "# Check if 'Loan_Status' column exists in the dataset\n",
        "if 'Loan_Status' not in train_data.columns:\n",
        "    # If 'Loan_Status' is missing, manually label the loan approval status\n",
        "    # Open the train dataset in a spreadsheet editor and add the 'Loan_Status' column with the appropriate labels\n",
        "\n",
        "    # Reload the train dataset with the manually labeled 'Loan_Status' column\n",
        "    train_data = pd.read_csv('train.csv')\n",
        "\n",
        "# Preprocessing\n",
        "# Perform any necessary data cleaning and feature engineering here\n",
        "\n",
        "# Select features and target variable\n",
        "features = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History']\n",
        "target = 'Loan_Status'\n",
        "\n",
        "# Separate the features and target variable\n",
        "X = train_data[features]\n",
        "y = train_data[target]\n",
        "\n",
        "# Split the data into train and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features using MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "# Train the model\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_pred = model.predict(X_val_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Validation Accuracy:\", accuracy)\n",
        "\n",
        "# Load the test dataset\n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "# Preprocessing for test data (similar to train data)\n",
        "# Perform any necessary data cleaning and feature engineering on the test dataset\n",
        "\n",
        "# Select features for the test data\n",
        "test_data_features = test_data[features]\n",
        "\n",
        "# Scale the test data features using the fitted scaler\n",
        "test_data_scaled = scaler.transform(test_data_features)\n",
        "\n",
        "# Predict on the test data\n",
        "test_predictions = model.predict(test_data_scaled)\n",
        "\n",
        "# Create submission file\n",
        "submission_df = pd.DataFrame({'Loan_ID': test_data['Loan_ID'], 'Loan_Status': test_predictions})\n",
        "submission_df['Loan_Status'] = submission_df['Loan_Status'].map({1: 'Y', 0: 'N'})\n",
        "submission_df.to_csv('submission.csv', index=False)\n"
      ],
      "metadata": {
        "id": "IG9WgtYjChfW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "87eed2fe-d272-4394-c9f7-6f40365f03d7"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-113050882439>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Predict on the validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         )\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1107\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load the train dataset\n",
        "train_data = pd.read_csv('train.csv')\n",
        "\n",
        "# Check if 'Loan_Status' column exists in the dataset\n",
        "if 'Loan_Status' not in train_data.columns:\n",
        "    # If 'Loan_Status' is missing, manually label the loan approval status\n",
        "    # Open the train dataset in a spreadsheet editor and add the 'Loan_Status' column with the appropriate labels\n",
        "\n",
        "    # Reload the train dataset with the manually labeled 'Loan_Status' column\n",
        "    train_data = pd.read_csv('train.csv')\n",
        "\n",
        "# Preprocessing\n",
        "# Perform any necessary data cleaning and feature engineering here\n",
        "\n",
        "# Select features and target variable\n",
        "features = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History']\n",
        "target = 'Loan_Status'\n",
        "\n",
        "# Separate the features and target variable\n",
        "X = train_data[features]\n",
        "y = train_data[target]\n",
        "\n",
        "# Split the data into train and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features using MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "# Impute missing values with mean\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train_imputed = imputer.fit_transform(X_train_scaled)\n",
        "X_val_imputed = imputer.transform(X_val_scaled)\n",
        "\n",
        "# Train the model\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train_imputed, y_train)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_pred = model.predict(X_val_imputed)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Validation Accuracy:\", accuracy)\n",
        "\n",
        "# Load the test dataset\n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "# Preprocessing for test data (similar to train data)\n",
        "# Perform any necessary data cleaning and feature engineering on the test dataset\n",
        "\n",
        "# Select features for the test data\n",
        "test_data_features = test_data[features]\n",
        "\n",
        "# Scale the test data features using the fitted scaler\n",
        "test_data_scaled = scaler.transform(test_data_features)\n",
        "\n",
        "# Impute missing values with mean\n",
        "test_data_imputed = imputer.transform(test_data_scaled)\n",
        "\n",
        "# Predict on the test data\n",
        "test_predictions = model.predict(test_data_imputed)\n",
        "\n",
        "# Create submission file\n",
        "submission_df = pd.DataFrame({'Loan_ID': test_data['Loan_ID'], 'Loan_Status': test_predictions})\n",
        "submission_df['Loan_Status'] = submission_df['Loan_Status'].map({1: 'Y', 0: 'N'})\n",
        "submission_df.to_csv('submission.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGA05r08EA2s",
        "outputId": "bcd55239-1237-4631-95d8-c9a4207be1d1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.7723577235772358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(y_val, y_pred, pos_label='Y')\n",
        "print(\"Precision:\", precision)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_val, y_pred, pos_label='Y')\n",
        "print(\"Recall:\", recall)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(y_val, y_pred, pos_label='Y')\n",
        "print(\"F1 Score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDdvccYJENk5",
        "outputId": "aa2d6d14-b186-423f-874f-ea65cbadfc84"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7723577235772358\n",
            "Precision: 0.7708333333333334\n",
            "Recall: 0.925\n",
            "F1 Score: 0.840909090909091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the train and test datasets separately\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "# Explore the train dataset\n",
        "# Example: Print the first few rows\n",
        "print(train_data.head())\n",
        "\n",
        "# Example: Print the summary statistics\n",
        "print(train_data.describe())\n",
        "\n",
        "# Example: Visualize the distribution of the target variable\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.countplot(x='Loan_Status', data=train_data)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9xxzktMJEb9B",
        "outputId": "3f45159b-6425-4b77-b23f-01dd0e7973c0"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
            "0  LP001002   Male      No          0      Graduate            No   \n",
            "1  LP001003   Male     Yes          1      Graduate            No   \n",
            "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
            "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
            "4  LP001008   Male      No          0      Graduate            No   \n",
            "\n",
            "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
            "0             5849                0.0         NaN             360.0   \n",
            "1             4583             1508.0       128.0             360.0   \n",
            "2             3000                0.0        66.0             360.0   \n",
            "3             2583             2358.0       120.0             360.0   \n",
            "4             6000                0.0       141.0             360.0   \n",
            "\n",
            "   Credit_History Property_Area Loan_Status  \n",
            "0             1.0         Urban           Y  \n",
            "1             1.0         Rural           N  \n",
            "2             1.0         Urban           Y  \n",
            "3             1.0         Urban           Y  \n",
            "4             1.0         Urban           Y  \n",
            "       ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
            "count       614.000000         614.000000  592.000000         600.00000   \n",
            "mean       5403.459283        1621.245798  146.412162         342.00000   \n",
            "std        6109.041673        2926.248369   85.587325          65.12041   \n",
            "min         150.000000           0.000000    9.000000          12.00000   \n",
            "25%        2877.500000           0.000000  100.000000         360.00000   \n",
            "50%        3812.500000        1188.500000  128.000000         360.00000   \n",
            "75%        5795.000000        2297.250000  168.000000         360.00000   \n",
            "max       81000.000000       41667.000000  700.000000         480.00000   \n",
            "\n",
            "       Credit_History  \n",
            "count      564.000000  \n",
            "mean         0.842199  \n",
            "std          0.364878  \n",
            "min          0.000000  \n",
            "25%          1.000000  \n",
            "50%          1.000000  \n",
            "75%          1.000000  \n",
            "max          1.000000  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAGwCAYAAABPSaTdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAr4klEQVR4nO3df1RVdb7/8dcBBEE4hwGBA1e0X5agoF119Ky63kZJRGpyoplyuEoTV28OdkcZleFmmvYDsxqtxh/ZmtRWOnbrZl2Zm0qWNCVaMTn+jJWON2zwQDeFozYeEM73j5b720nNQvAcPj4fa+212J/PZ3/2e7OWnVd7f87G5vP5fAIAADBUSKALAAAA6EyEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAo4UFuoBg0NbWprq6OsXExMhmswW6HAAA8B34fD4dP35cKSkpCgk5//0bwo6kuro6paamBroMAADQDocPH1avXr3O20/YkRQTEyPpq1+W3W4PcDUAAOC78Hg8Sk1NtT7Hz4ewI1mPrux2O2EHAIAu5kJLUFigDAAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADBaWKALuFwMnvlCoEsAglL14xMDXQIAw3FnBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRgibsLFiwQDabTdOmTbPaTp06paKiIsXHxys6Olp5eXmqr6/3O662tla5ubmKiopSYmKiZs6cqdOnT1/i6gEAQLAKirDzwQcf6Nlnn1VmZqZf+/Tp07Vhwwa9/PLLqqysVF1dnW6//Xarv7W1Vbm5uWpubta2bdu0evVqrVq1SnPmzLnUlwAAAIJUwMPOiRMnlJ+fr+eee04/+MEPrPampib9/ve/129/+1uNHDlSgwcP1sqVK7Vt2zZt375dkrR582bt27dPL774ogYNGqScnBw99NBDWrJkiZqbmwN1SQAAIIgEPOwUFRUpNzdXWVlZfu3V1dVqaWnxa+/Xr5969+6tqqoqSVJVVZUyMjKUlJRkjcnOzpbH49HevXvPe06v1yuPx+O3AQAAM4UF8uTr1q3Tn//8Z33wwQdn9bndboWHhys2NtavPSkpSW632xrz9aBzpv9M3/mUlZVp3rx5F1k9AADoCgJ2Z+fw4cP61a9+pTVr1qh79+6X9NylpaVqamqytsOHD1/S8wMAgEsnYGGnurpaDQ0N+sd//EeFhYUpLCxMlZWVevrppxUWFqakpCQ1NzersbHR77j6+no5nU5JktPpPOvbWWf2z4w5l4iICNntdr8NAACYKWBhZ9SoUdq9e7d27txpbUOGDFF+fr71c7du3bRlyxbrmJqaGtXW1srlckmSXC6Xdu/erYaGBmtMRUWF7Ha70tPTL/k1AQCA4BOwNTsxMTEaMGCAX1uPHj0UHx9vtRcWFqq4uFhxcXGy2+2677775HK5NHz4cEnS6NGjlZ6ergkTJmjhwoVyu92aPXu2ioqKFBERccmvCQAABJ+ALlC+kEWLFikkJER5eXnyer3Kzs7W0qVLrf7Q0FCVl5drypQpcrlc6tGjhwoKCjR//vwAVg0AAIKJzefz+QJdRKB5PB45HA41NTV12vqdwTNf6JR5ga6u+vGJgS4BQBf1XT+/A/6eHQAAgM5E2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMFpAw86yZcuUmZkpu90uu90ul8ulN954w+q/6aabZLPZ/LZ7773Xb47a2lrl5uYqKipKiYmJmjlzpk6fPn2pLwUAAASpsECevFevXlqwYIH69u0rn8+n1atX67bbbtNHH32k/v37S5ImTZqk+fPnW8dERUVZP7e2tio3N1dOp1Pbtm3TkSNHNHHiRHXr1k2PPvroJb8eAAAQfAIadm699Va//UceeUTLli3T9u3brbATFRUlp9N5zuM3b96sffv26c0331RSUpIGDRqkhx56SCUlJXrwwQcVHh7e6dcAAACCW9Cs2WltbdW6det08uRJuVwuq33NmjXq2bOnBgwYoNLSUn355ZdWX1VVlTIyMpSUlGS1ZWdny+PxaO/evec9l9frlcfj8dsAAICZAnpnR5J2794tl8ulU6dOKTo6WuvXr1d6erok6ec//7n69OmjlJQU7dq1SyUlJaqpqdGrr74qSXK73X5BR5K173a7z3vOsrIyzZs3r5OuCAAABJOAh53rrrtOO3fuVFNTk1555RUVFBSosrJS6enpmjx5sjUuIyNDycnJGjVqlA4ePKirr7663ecsLS1VcXGxte/xeJSamnpR1wEAAIJTwB9jhYeH65prrtHgwYNVVlamgQMH6qmnnjrn2GHDhkmSDhw4IElyOp2qr6/3G3Nm/3zrfCQpIiLC+gbYmQ0AAJgp4GHnm9ra2uT1es/Zt3PnTklScnKyJMnlcmn37t1qaGiwxlRUVMhut1uPwgAAwOUtoI+xSktLlZOTo969e+v48eNau3attm7dqk2bNungwYNau3atxo4dq/j4eO3atUvTp0/XiBEjlJmZKUkaPXq00tPTNWHCBC1cuFBut1uzZ89WUVGRIiIiAnlpAAAgSAQ07DQ0NGjixIk6cuSIHA6HMjMztWnTJt188806fPiw3nzzTS1evFgnT55Uamqq8vLyNHv2bOv40NBQlZeXa8qUKXK5XOrRo4cKCgr83ssDAAAubzafz+cLdBGB5vF45HA41NTU1GnrdwbPfKFT5gW6uurHJwa6BABd1Hf9/A66NTsAAAAdibADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGC0gIadZcuWKTMzU3a7XXa7XS6XS2+88YbVf+rUKRUVFSk+Pl7R0dHKy8tTfX293xy1tbXKzc1VVFSUEhMTNXPmTJ0+ffpSXwoAAAhSAQ07vXr10oIFC1RdXa0PP/xQI0eO1G233aa9e/dKkqZPn64NGzbo5ZdfVmVlperq6nT77bdbx7e2tio3N1fNzc3atm2bVq9erVWrVmnOnDmBuiQAABBkbD6fzxfoIr4uLi5Ojz/+uO644w4lJCRo7dq1uuOOOyRJH3/8sdLS0lRVVaXhw4frjTfe0C233KK6ujolJSVJkpYvX66SkhJ9/vnnCg8PP+c5vF6vvF6vte/xeJSamqqmpibZ7fZOua7BM1/olHmBrq768YmBLgFAF+XxeORwOC74+R00a3ZaW1u1bt06nTx5Ui6XS9XV1WppaVFWVpY1pl+/furdu7eqqqokSVVVVcrIyLCCjiRlZ2fL4/FYd4fOpaysTA6Hw9pSU1M778IAAEBABTzs7N69W9HR0YqIiNC9996r9evXKz09XW63W+Hh4YqNjfUbn5SUJLfbLUlyu91+QedM/5m+8yktLVVTU5O1HT58uGMvCgAABI2wQBdw3XXXaefOnWpqatIrr7yigoICVVZWduo5IyIiFBER0annAAAAwSHgYSc8PFzXXHONJGnw4MH64IMP9NRTT+nOO+9Uc3OzGhsb/e7u1NfXy+l0SpKcTqfef/99v/nOfFvrzBgAAHB5C/hjrG9qa2uT1+vV4MGD1a1bN23ZssXqq6mpUW1trVwulyTJ5XJp9+7damhosMZUVFTIbrcrPT39ktcOAACCT0Dv7JSWlionJ0e9e/fW8ePHtXbtWm3dulWbNm2Sw+FQYWGhiouLFRcXJ7vdrvvuu08ul0vDhw+XJI0ePVrp6emaMGGCFi5cKLfbrdmzZ6uoqIjHVAAAQFKAw05DQ4MmTpyoI0eOyOFwKDMzU5s2bdLNN98sSVq0aJFCQkKUl5cnr9er7OxsLV261Do+NDRU5eXlmjJlilwul3r06KGCggLNnz8/UJcEAACCTNC9ZycQvuv39C8G79kBzo337ABory73nh0AAIDOQNgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADBaQMNOWVmZhg4dqpiYGCUmJmrcuHGqqanxG3PTTTfJZrP5bffee6/fmNraWuXm5ioqKkqJiYmaOXOmTp8+fSkvBQAABKmwQJ68srJSRUVFGjp0qE6fPq3/+I//0OjRo7Vv3z716NHDGjdp0iTNnz/f2o+KirJ+bm1tVW5urpxOp7Zt26YjR45o4sSJ6tatmx599NFLej0AACD4BDTsbNy40W9/1apVSkxMVHV1tUaMGGG1R0VFyel0nnOOzZs3a9++fXrzzTeVlJSkQYMG6aGHHlJJSYkefPBBhYeHn3WM1+uV1+u19j0eTwddEQAACDZBtWanqalJkhQXF+fXvmbNGvXs2VMDBgxQaWmpvvzyS6uvqqpKGRkZSkpKstqys7Pl8Xi0d+/ec56nrKxMDofD2lJTUzvhagAAQDAI6J2dr2tra9O0adN0ww03aMCAAVb7z3/+c/Xp00cpKSnatWuXSkpKVFNTo1dffVWS5Ha7/YKOJGvf7Xaf81ylpaUqLi629j0eD4EHAABDBU3YKSoq0p49e/Tuu+/6tU+ePNn6OSMjQ8nJyRo1apQOHjyoq6++ul3nioiIUERExEXVCwAAuoageIw1depUlZeX6+2331avXr2+deywYcMkSQcOHJAkOZ1O1dfX+405s3++dT4AAODyEdCw4/P5NHXqVK1fv15vvfWWrrzyygses3PnTklScnKyJMnlcmn37t1qaGiwxlRUVMhutys9Pb1T6gYAAF1HQB9jFRUVae3atXr99dcVExNjrbFxOByKjIzUwYMHtXbtWo0dO1bx8fHatWuXpk+frhEjRigzM1OSNHr0aKWnp2vChAlauHCh3G63Zs+eraKiIh5VAQCAwN7ZWbZsmZqamnTTTTcpOTnZ2l566SVJUnh4uN58802NHj1a/fr1069//Wvl5eVpw4YN1hyhoaEqLy9XaGioXC6X/uVf/kUTJ070ey8PAAC4fLXrzs7IkSP16quvKjY21q/d4/Fo3Lhxeuutt77TPD6f71v7U1NTVVlZecF5+vTpo//5n//5TucEAACXl3bd2dm6dauam5vPaj916pT+9Kc/XXRRAAAAHeV73dnZtWuX9fO+ffv83mPT2tqqjRs36h/+4R86rjoAAICL9L3CzqBBg6w/xjly5Miz+iMjI/XMM890WHEAAAAX63uFnUOHDsnn8+mqq67S+++/r4SEBKsvPDxciYmJCg0N7fAiAQAA2ut7hZ0+ffpI+upPOwAAAHQF7X7PzieffKK3335bDQ0NZ4WfOXPmXHRhAAAAHaFdYee5557TlClT1LNnTzmdTtlsNqvPZrMRdgAAQNBoV9h5+OGH9cgjj6ikpKSj6wEAAOhQ7XrPzrFjx/TTn/60o2sBAADocO0KOz/96U+1efPmjq4FAACgw7XrMdY111yjBx54QNu3b1dGRoa6devm1//v//7vHVIcAADAxWpX2FmxYoWio6NVWVl51t+ustlshB0AABA02hV2Dh061NF1AAAAdIp2rdkBAADoKtp1Z+eee+751v7nn3++XcUAAAB0tHaFnWPHjvntt7S0aM+ePWpsbDznHwgFAAAIlHaFnfXr15/V1tbWpilTpujqq6++6KIAAAA6Soet2QkJCVFxcbEWLVrUUVMCAABctA5doHzw4EGdPn26I6cEAAC4KO16jFVcXOy37/P5dOTIEf3xj39UQUFBhxQGAADQEdoVdj766CO//ZCQECUkJOjJJ5+84De1AAAALqV2hZ233367o+sAAADoFO0KO2d8/vnnqqmpkSRdd911SkhI6JCiAAAAOkq7FiifPHlS99xzj5KTkzVixAiNGDFCKSkpKiws1JdfftnRNQIAALRbu8JOcXGxKisrtWHDBjU2NqqxsVGvv/66Kisr9etf/7qjawQAAGi3dj3G+q//+i+98soruummm6y2sWPHKjIyUj/72c+0bNmyjqoPAADgorTrzs6XX36ppKSks9oTExN5jAUAAIJKu8KOy+XS3LlzderUKavt73//u+bNmyeXy9VhxQEAAFysdj3GWrx4scaMGaNevXpp4MCBkqS//OUvioiI0ObNmzu0QAAAgIvRrrCTkZGhTz75RGvWrNHHH38sSRo/frzy8/MVGRnZoQUCAABcjHY9xiorK9O6des0adIkPfnkk3ryySf1r//6r/rDH/6gxx577HvNM3ToUMXExCgxMVHjxo2z3ttzxqlTp1RUVKT4+HhFR0crLy9P9fX1fmNqa2uVm5urqKgoJSYmaubMmfyNLgAAIKmdYefZZ59Vv379zmrv37+/li9f/p3nqaysVFFRkbZv366Kigq1tLRo9OjROnnypDVm+vTp2rBhg15++WVVVlaqrq5Ot99+u9Xf2tqq3NxcNTc3a9u2bVq9erVWrVqlOXPmtOfSAACAYWw+n8/3fQ/q3r279u/fryuvvNKv/a9//avS09P9Fi5/H59//rkSExNVWVmpESNGqKmpSQkJCVq7dq3uuOMOSdLHH3+stLQ0VVVVafjw4XrjjTd0yy23qK6uzvqG2PLly1VSUqLPP/9c4eHhFzyvx+ORw+FQU1OT7HZ7u2q/kMEzX+iUeYGurvrxiYEuAUAX9V0/v9t1Zyc1NVXvvffeWe3vvfeeUlJS2jOlJKmpqUmSFBcXJ0mqrq5WS0uLsrKyrDH9+vVT7969VVVVJUmqqqpSRkaG31fhs7Oz5fF4tHfv3nOex+v1yuPx+G0AAMBM7VqgPGnSJE2bNk0tLS0aOXKkJGnLli2aNWtWu9+g3NbWpmnTpumGG27QgAEDJElut1vh4eGKjY31G5uUlCS3222N+eY7f87snxnzTWVlZZo3b1676gQAAF1Lu8LOzJkz9cUXX+iXv/ylmpubJX31aKukpESlpaXtKqSoqEh79uzRu+++267jv4/S0lIVFxdb+x6PR6mpqZ1+XgAAcOm1K+zYbDY99thjeuCBB7R//35FRkaqb9++ioiIaFcRU6dOVXl5ud555x316tXLanc6nWpublZjY6Pf3Z36+no5nU5rzPvvv+8335lva50Z800RERHtrhUAAHQt7Vqzc0Z0dLSGDh2qAQMGtCs8+Hw+TZ06VevXr9dbb7111oLnwYMHq1u3btqyZYvVVlNTo9raWutNzS6XS7t371ZDQ4M1pqKiQna7Xenp6e28MgAAYIp23dnpKEVFRVq7dq1ef/11xcTEWGtsHA6HIiMj5XA4VFhYqOLiYsXFxclut+u+++6Ty+XS8OHDJUmjR49Wenq6JkyYoIULF8rtdmv27NkqKiri7g0AAAhs2Dnz19G//tfTJWnlypW6++67JUmLFi1SSEiI8vLy5PV6lZ2draVLl1pjQ0NDVV5erilTpsjlcqlHjx4qKCjQ/PnzL9VlAACAINau9+yYhvfsAIHDe3YAtNd3/fwO6J0dADBB7fyMQJcABKXec3YHugRJF7lAGQAAINgRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGC2gYeedd97RrbfeqpSUFNlsNr322mt+/XfffbdsNpvfNmbMGL8xR48eVX5+vux2u2JjY1VYWKgTJ05cwqsAAADBLKBh5+TJkxo4cKCWLFly3jFjxozRkSNHrO0Pf/iDX39+fr727t2riooKlZeX65133tHkyZM7u3QAANBFhAXy5Dk5OcrJyfnWMREREXI6nefs279/vzZu3KgPPvhAQ4YMkSQ988wzGjt2rJ544gmlpKR0eM0AAKBrCfo1O1u3blViYqKuu+46TZkyRV988YXVV1VVpdjYWCvoSFJWVpZCQkK0Y8eO887p9Xrl8Xj8NgAAYKagDjtjxozRCy+8oC1btuixxx5TZWWlcnJy1NraKklyu91KTEz0OyYsLExxcXFyu93nnbesrEwOh8PaUlNTO/U6AABA4AT0MdaF3HXXXdbPGRkZyszM1NVXX62tW7dq1KhR7Z63tLRUxcXF1r7H4yHwAABgqKC+s/NNV111lXr27KkDBw5IkpxOpxoaGvzGnD59WkePHj3vOh/pq3VAdrvdbwMAAGbqUmHns88+0xdffKHk5GRJksvlUmNjo6qrq60xb731ltra2jRs2LBAlQkAAIJIQB9jnThxwrpLI0mHDh3Szp07FRcXp7i4OM2bN095eXlyOp06ePCgZs2apWuuuUbZ2dmSpLS0NI0ZM0aTJk3S8uXL1dLSoqlTp+quu+7im1gAAEBSgO/sfPjhh7r++ut1/fXXS5KKi4t1/fXXa86cOQoNDdWuXbv04x//WNdee60KCws1ePBg/elPf1JERIQ1x5o1a9SvXz+NGjVKY8eO1Y033qgVK1YE6pIAAECQCeidnZtuukk+n++8/Zs2bbrgHHFxcVq7dm1HlgUAAAzSpdbsAAAAfF+EHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAowU07Lzzzju69dZblZKSIpvNptdee82v3+fzac6cOUpOTlZkZKSysrL0ySef+I05evSo8vPzZbfbFRsbq8LCQp04ceISXgUAAAhmAQ07J0+e1MCBA7VkyZJz9i9cuFBPP/20li9frh07dqhHjx7Kzs7WqVOnrDH5+fnau3evKioqVF5ernfeeUeTJ0++VJcAAACCXFggT56Tk6OcnJxz9vl8Pi1evFizZ8/WbbfdJkl64YUXlJSUpNdee0133XWX9u/fr40bN+qDDz7QkCFDJEnPPPOMxo4dqyeeeEIpKSnnnNvr9crr9Vr7Ho+ng68MAAAEi6Bds3Po0CG53W5lZWVZbQ6HQ8OGDVNVVZUkqaqqSrGxsVbQkaSsrCyFhIRox44d5527rKxMDofD2lJTUzvvQgAAQEAFbdhxu92SpKSkJL/2pKQkq8/tdisxMdGvPywsTHFxcdaYcyktLVVTU5O1HT58uIOrBwAAwSKgj7ECJSIiQhEREYEuAwAAXAJBe2fH6XRKkurr6/3a6+vrrT6n06mGhga//tOnT+vo0aPWGAAAcHkL2rBz5ZVXyul0asuWLVabx+PRjh075HK5JEkul0uNjY2qrq62xrz11ltqa2vTsGHDLnnNAAAg+AT0MdaJEyd04MABa//QoUPauXOn4uLi1Lt3b02bNk0PP/yw+vbtqyuvvFIPPPCAUlJSNG7cOElSWlqaxowZo0mTJmn58uVqaWnR1KlTddddd533m1gAAODyEtCw8+GHH+pHP/qRtV9cXCxJKigo0KpVqzRr1iydPHlSkydPVmNjo2688UZt3LhR3bt3t45Zs2aNpk6dqlGjRikkJER5eXl6+umnL/m1AACA4GTz+Xy+QBcRaB6PRw6HQ01NTbLb7Z1yjsEzX+iUeYGurvrxiYEu4aLVzs8IdAlAUOo9Z3enzv9dP7+Dds0OAABARyDsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwWlCHnQcffFA2m81v69evn9V/6tQpFRUVKT4+XtHR0crLy1N9fX0AKwYAAMEmqMOOJPXv319Hjhyxtnfffdfqmz59ujZs2KCXX35ZlZWVqqur0+233x7AagEAQLAJC3QBFxIWFian03lWe1NTk37/+99r7dq1GjlypCRp5cqVSktL0/bt2zV8+PBLXSoAAAhCQX9n55NPPlFKSoquuuoq5efnq7a2VpJUXV2tlpYWZWVlWWP79eun3r17q6qq6lvn9Hq98ng8fhsAADBTUIedYcOGadWqVdq4caOWLVumQ4cO6Z/+6Z90/Phxud1uhYeHKzY21u+YpKQkud3ub523rKxMDofD2lJTUzvxKgAAQCAF9WOsnJwc6+fMzEwNGzZMffr00X/+538qMjKy3fOWlpaquLjY2vd4PAQeAAAMFdR3dr4pNjZW1157rQ4cOCCn06nm5mY1Njb6jamvrz/nGp+vi4iIkN1u99sAAICZulTYOXHihA4ePKjk5GQNHjxY3bp105YtW6z+mpoa1dbWyuVyBbBKAAAQTIL6MdaMGTN06623qk+fPqqrq9PcuXMVGhqq8ePHy+FwqLCwUMXFxYqLi5Pdbtd9990nl8vFN7EAAIAlqMPOZ599pvHjx+uLL75QQkKCbrzxRm3fvl0JCQmSpEWLFikkJER5eXnyer3Kzs7W0qVLA1w1AAAIJkEddtatW/et/d27d9eSJUu0ZMmSS1QRAADoarrUmh0AAIDvi7ADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0Y8LOkiVLdMUVV6h79+4aNmyY3n///UCXBAAAgoARYeell15ScXGx5s6dqz//+c8aOHCgsrOz1dDQEOjSAABAgBkRdn77299q0qRJ+sUvfqH09HQtX75cUVFRev755wNdGgAACLCwQBdwsZqbm1VdXa3S0lKrLSQkRFlZWaqqqjrnMV6vV16v19pvamqSJHk8nk6rs9X7906bG+jKOvPf3aVy/FRroEsAglJn//s+M7/P5/vWcV0+7Pzf//2fWltblZSU5NeelJSkjz/++JzHlJWVad68eWe1p6amdkqNAM7P8cy9gS4BQGcpc1yS0xw/flwOx/nP1eXDTnuUlpaquLjY2m9ra9PRo0cVHx8vm80WwMpwKXg8HqWmpurw4cOy2+2BLgdAB+Lf9+XF5/Pp+PHjSklJ+dZxXT7s9OzZU6Ghoaqvr/drr6+vl9PpPOcxERERioiI8GuLjY3trBIRpOx2O/8xBAzFv+/Lx7fd0Tmjyy9QDg8P1+DBg7Vlyxarra2tTVu2bJHL5QpgZQAAIBh0+Ts7klRcXKyCggINGTJEP/zhD7V48WKdPHlSv/jFLwJdGgAACDAjws6dd96pzz//XHPmzJHb7dagQYO0cePGsxYtA9JXjzHnzp171qNMAF0f/75xLjbfhb6vBQAA0IV1+TU7AAAA34awAwAAjEbYAQAARiPsAAAAoxF2YDyfz6esrCxlZ2ef1bd06VLFxsbqs88+C0BlADrC3XffLZvNpgULFvi1v/baa7wVH5IIO7gM2Gw2rVy5Ujt27NCzzz5rtR86dEizZs3SM888o169egWwQgAXq3v37nrsscd07NixQJeCIETYwWUhNTVVTz31lGbMmKFDhw7J5/OpsLBQo0eP1oQJEwJdHoCLlJWVJafTqbKyskCXgiBE2MFlo6CgQKNGjdI999yj3/3ud9qzZ4/fnR4AXVdoaKgeffRRPfPMMzyWxlkIO7isrFixQnv27NG0adO0YsUKJSQkBLokAB3kJz/5iQYNGqS5c+cGuhQEGcIOLiuJiYn6t3/7N6WlpWncuHGBLgdAB3vssce0evVq7d+/P9ClIIgQdnDZCQsLU1iYEX8WDsA3jBgxQtnZ2SotLQ10KQgi/BcfAGCUBQsWaNCgQbruuusCXQqCBHd2AABGycjIUH5+vp5++ulAl4IgQdgBABhn/vz5amtrC3QZCBI2n8/nC3QRAAAAnYU7OwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdABfl7rvv1rhx4wJdxnk999xzGjhwoKKjoxUbG6vrr79eZWVlVn9763/wwQc1aNCgjisUQKfhr54DMNbzzz+vadOm6emnn9Y///M/y+v1ateuXdqzZ0+gSwNwCXFnB0Cnqays1A9/+ENFREQoOTlZv/nNb3T69Gmrf+PGjbrxxhsVGxur+Ph43XLLLTp48KDV/7//+7+y2Wx69dVX9aMf/UhRUVEaOHCgqqqqvtP5//u//1s/+9nPVFhYqGuuuUb9+/fX+PHj9cgjj0j66u7M6tWr9frrr8tms8lms2nr1q2SpJKSEl177bWKiorSVVddpQceeEAtLS2SpFWrVmnevHn6y1/+Yh23atUqq96dO3daNTQ2NvrNe+zYMeXn5yshIUGRkZHq27evVq5ceRG/ZQAXwp0dAJ3ib3/7m8aOHau7775bL7zwgj7++GNNmjRJ3bt314MPPihJOnnypIqLi5WZmakTJ05ozpw5+slPfqKdO3cqJOT//7/Y/fffryeeeEJ9+/bV/fffr/Hjx+vAgQMKC/v2/4Q5nU5VVlbq008/VZ8+fc7qnzFjhvbv3y+Px2MFjri4OElSTEyMVq1apZSUFO3evVuTJk1STEyMZs2apTvvvFN79uzRxo0b9eabb0qSHA6H6uvrL/h7eeCBB7Rv3z698cYb6tmzpw4cOKC///3v3+l3CqB9CDsAOsXSpUuVmpqq3/3ud7LZbOrXr5/q6upUUlKiOXPmKCQkRHl5eX7HPP/880pISNC+ffs0YMAAq33GjBnKzc2VJM2bN0/9+/fXgQMH1K9fv2+tYe7cubr99tt1xRVX6Nprr5XL5dLYsWN1xx13KCQkRNHR0YqMjJTX65XT6fQ7dvbs2dbPV1xxhWbMmKF169Zp1qxZioyMVHR0tMLCws467kJqa2t1/fXXa8iQIdbcADoXj7EAdIr9+/fL5XLJZrNZbTfccINOnDihzz77TJL0ySefaPz48brqqqtkt9utD/7a2lq/uTIzM62fk5OTJUkNDQ0XrCE5OVlVVVXavXu3fvWrX+n06dMqKCjQmDFj1NbW9q3HvvTSS7rhhhvkdDoVHR2t2bNnn1VXe0yZMkXr1q3ToEGDNGvWLG3btu2i5wTw7Qg7AALm1ltv1dGjR/Xcc89px44d2rFjhySpubnZb1y3bt2sn8+EpwuFla8bMGCAfvnLX+rFF19URUWFKioqVFlZed7xVVVVys/P19ixY1VeXq6PPvpI999//1l1fdOZR28+n89qO7PO54ycnBx9+umnmj59uurq6jRq1CjNmDHjO18LgO+PsAOgU6Slpamqqsrvg/+9995TTEyMevXqpS+++EI1NTWaPXu2Ro0apbS0NB07dqzT60pPT5f01XohSQoPD1dra6vfmG3btqlPnz66//77NWTIEPXt21effvqp35hzHZeQkCBJOnLkiNX29cXKXx9XUFCgF198UYsXL9aKFSsu+roAnB9rdgBctKamprM+1CdPnqzFixfrvvvu09SpU1VTU6O5c+equLhYISEh+sEPfqD4+HitWLFCycnJqq2t1W9+85sOrWvKlClKSUnRyJEj1atXLx05ckQPP/ywEhIS5HK5JH21ZmbTpk2qqalRfHy8HA6H+vbtq9raWq1bt05Dhw7VH//4R61fv95v7iuuuEKHDh3Szp071atXL8XExCgyMlLDhw/XggULdOWVV6qhocFv7Y8kzZkzR4MHD1b//v3l9XpVXl6utLS0Dr1uAN/gA4CLUFBQ4JN01lZYWOjbunWrb+jQob7w8HCf0+n0lZSU+FpaWqxjKyoqfGlpab6IiAhfZmamb+vWrT5JvvXr1/t8Pp/v0KFDPkm+jz76yDrm2LFjPkm+t99++4K1vfLKK76xY8f6kpOTfeHh4b6UlBRfXl6eb9euXdaYhoYG38033+yLjo72m3fmzJm++Ph4X3R0tO/OO+/0LVq0yOdwOKzjTp065cvLy/PFxsb6JPlWrlzp8/l8vn379vlcLpcvMjLSN2jQIN/mzZv95n3ooYd8aWlpvsjISF9cXJzvtttu8/31r39tz68ewHdk8/m+do8ZAADAMKzZAQAARiPsAOiycnJyFB0dfc7t0UcfDXR5AIIEj7EAdFl/+9vfzvv24bi4OOttyAAub4QdAABgNB5jAQAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACM9v8AlTcUPp8ko+UAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate the features and target variable for the train dataset\n",
        "X_train = train_data.drop('Loan_Status', axis=1)\n",
        "y_train = train_data['Loan_Status']\n",
        "\n",
        "# Separate the features for the test dataset\n",
        "X_test = test_data.copy()\n",
        "\n",
        "# Perform any necessary pre-processing steps (e.g., handling missing values, encoding categorical variables, scaling numeric variables)\n",
        "\n",
        "# Example: Handle missing values using SimpleImputer from sklearn\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Create an imputer object\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "# Impute missing values in the train dataset\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "\n",
        "# Impute missing values in the test dataset\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "# Example: Encode categorical variables using OneHotEncoder from sklearn\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# Create an instance of the OneHotEncoder with handle_unknown='ignore'\n",
        "encoder = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "# Encode categorical variables in the train dataset\n",
        "X_train_encoded = encoder.fit_transform(X_train_imputed[:, categorical_indices])\n",
        "\n",
        "# Encode categorical variables in the test dataset\n",
        "X_test_encoded = encoder.transform(X_test_imputed[:, categorical_indices])\n",
        "\n",
        "# Create an encoder object\n",
        "encoder = OneHotEncoder(drop='first', sparse=False)\n",
        "\n",
        "# Encode categorical variables in the train dataset\n",
        "X_train_encoded = encoder.fit_transform(X_train_imputed[:, categorical_indices])\n",
        "\n",
        "# Encode categorical variables in the test dataset\n",
        "X_test_encoded = encoder.transform(X_test_imputed[:, categorical_indices])\n",
        "\n",
        "# Example: Scale numeric variables using MinMaxScaler from sklearn\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Create a scaler object\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Scale numeric variables in the train dataset\n",
        "X_train_scaled = scaler.fit_transform(X_train_imputed[:, numeric_indices])\n",
        "\n",
        "# Scale numeric variables in the test dataset\n",
        "X_test_scaled = scaler.transform(X_test_imputed[:, numeric_indices])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "n_IWCutSPAv5",
        "outputId": "c277bd7c-de3b-44aa-dd32-a814db624e10"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-aecbade3ace9>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Encode categorical variables in the test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mX_test_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_imputed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Example: Scale numeric variables using MinMaxScaler from sklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0;34m\"infrequent_if_exist\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m         }\n\u001b[0;32m--> 917\u001b[0;31m         X_int, X_mask = self._transform(\n\u001b[0m\u001b[1;32m    918\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, X, handle_unknown, force_all_finite, warn_on_unknown)\u001b[0m\n\u001b[1;32m    172\u001b[0m                         \u001b[0;34m\" during transform\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                     )\n\u001b[0;32m--> 174\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mwarn_on_unknown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found unknown categories ['LP001094', 'LP001587', 'LP002954', 'LP001176', 'LP002064', 'LP001853', 'LP001975', 'LP001490', 'LP002339', 'LP002389', 'LP002711', 'LP001548', 'LP001737', 'LP002869', 'LP001791', 'LP002346', 'LP001651', 'LP001230', 'LP002385', 'LP002450', 'LP001867', 'LP001096', 'LP002485', 'LP002376', 'LP001718', 'LP002769', 'LP001573', 'LP002442', 'LP002441', 'LP001210', 'LP002107', 'LP002593', 'LP002399', 'LP002172', 'LP002482', 'LP002654', 'LP001881', 'LP002989', 'LP001359', 'LP002007', 'LP001022', 'LP001226', 'LP002639', 'LP001450', 'LP001135', 'LP002975', 'LP001231', 'LP001317', 'LP001056', 'LP002270', 'LP002069', 'LP002867', 'LP002644', 'LP001561', 'LP001268', 'LP001815', 'LP001298', 'LP002286', 'LP002584', 'LP002605', 'LP002657', 'LP001466', 'LP002375', 'LP001242', 'LP002550', 'LP002849', 'LP002311', 'LP001219', 'LP001794', 'LP002165', 'LP002986', 'LP001015', 'LP002635', 'LP001789', 'LP001108', 'LP002027', 'LP001031', 'LP001886', 'LP001035', 'LP002775', 'LP002774', 'LP001472', 'LP002879', 'LP002325', 'LP001655', 'LP002793', 'LP001660', 'LP002850', 'LP001662', 'LP001149', 'LP001950', 'LP001348', 'LP001347', 'LP001862', 'LP001906', 'LP002610', 'LP001527', 'LP002045', 'LP002176', 'LP002118', 'LP002183', 'LP002857', 'LP001163', 'LP001584', 'LP002316', 'LP002306', 'LP001174', 'LP002062', 'LP002298', 'LP002816', 'LP002412', 'LP002553', 'LP001785', 'LP002310', 'LP001667', 'LP001589', 'LP001284', 'LP001787', 'LP002402', 'LP001742', 'LP00284..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('train.csv')\n",
        "\n",
        "# Exploratory Data Analysis\n",
        "print(data.head())  # Display the first few rows of the dataset\n",
        "print(data.info())  # View the summary of the dataset\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('Loan_Status', axis=1)\n",
        "y = data['Loan_Status']\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Identify categorical and numerical features\n",
        "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
        "numerical_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Impute missing values in categorical features with the mode\n",
        "imputer_categorical = SimpleImputer(strategy='most_frequent')\n",
        "X_train_imputed_cat = imputer_categorical.fit_transform(X_train[categorical_features])\n",
        "X_test_imputed_cat = imputer_categorical.transform(X_test[categorical_features])\n",
        "\n",
        "# Impute missing values in numerical features with the mean\n",
        "imputer_numerical = SimpleImputer(strategy='mean')\n",
        "X_train_imputed_num = imputer_numerical.fit_transform(X_train[numerical_features])\n",
        "X_test_imputed_num = imputer_numerical.transform(X_test[numerical_features])\n",
        "\n",
        "# Combine imputed categorical and numerical features\n",
        "X_train_imputed = pd.DataFrame(data=X_train_imputed_num, columns=numerical_features)\n",
        "X_train_imputed = pd.concat([X_train_imputed, pd.DataFrame(data=X_train_imputed_cat, columns=categorical_features)], axis=1)\n",
        "\n",
        "X_test_imputed = pd.DataFrame(data=X_test_imputed_num, columns=numerical_features)\n",
        "X_test_imputed = pd.concat([X_test_imputed, pd.DataFrame(data=X_test_imputed_cat, columns=categorical_features)], axis=1)\n",
        "\n",
        "# One-hot encode categorical variables in the train dataset\n",
        "X_train_encoded = pd.get_dummies(X_train_imputed, columns=categorical_features, drop_first=True)\n",
        "\n",
        "# One-hot encode categorical variables in the test dataset\n",
        "X_test_encoded = pd.get_dummies(X_test_imputed, columns=categorical_features, drop_first=True)\n",
        "\n",
        "# Scale the numerical variables using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_encoded[numerical_features])\n",
        "X_test_scaled = scaler.transform(X_test_encoded[numerical_features])\n",
        "\n",
        "# Combine scaled numerical features with encoded categorical features\n",
        "X_train_final = pd.concat([pd.DataFrame(X_train_scaled, columns=numerical_features), X_train_encoded.drop(columns=numerical_features)], axis=1)\n",
        "X_test_final = pd.concat([pd.DataFrame(X_test_scaled, columns=numerical_features), X_test_encoded.drop(columns=numerical_features)], axis=1)\n",
        "\n",
        "# Now you can proceed with modeling using X_train_final and y_train\n",
        "# Remember to fit the model, perform fine-tuning, and evaluate the performance\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XWmOKUPPNbR",
        "outputId": "c243a60e-d2b3-45ff-a9fe-92c62ae9d548"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
            "0  LP001002   Male      No          0      Graduate            No   \n",
            "1  LP001003   Male     Yes          1      Graduate            No   \n",
            "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
            "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
            "4  LP001008   Male      No          0      Graduate            No   \n",
            "\n",
            "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
            "0             5849                0.0         NaN             360.0   \n",
            "1             4583             1508.0       128.0             360.0   \n",
            "2             3000                0.0        66.0             360.0   \n",
            "3             2583             2358.0       120.0             360.0   \n",
            "4             6000                0.0       141.0             360.0   \n",
            "\n",
            "   Credit_History Property_Area Loan_Status  \n",
            "0             1.0         Urban           Y  \n",
            "1             1.0         Rural           N  \n",
            "2             1.0         Urban           Y  \n",
            "3             1.0         Urban           Y  \n",
            "4             1.0         Urban           Y  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 614 entries, 0 to 613\n",
            "Data columns (total 13 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   Loan_ID            614 non-null    object \n",
            " 1   Gender             601 non-null    object \n",
            " 2   Married            611 non-null    object \n",
            " 3   Dependents         599 non-null    object \n",
            " 4   Education          614 non-null    object \n",
            " 5   Self_Employed      582 non-null    object \n",
            " 6   ApplicantIncome    614 non-null    int64  \n",
            " 7   CoapplicantIncome  614 non-null    float64\n",
            " 8   LoanAmount         592 non-null    float64\n",
            " 9   Loan_Amount_Term   600 non-null    float64\n",
            " 10  Credit_History     564 non-null    float64\n",
            " 11  Property_Area      614 non-null    object \n",
            " 12  Loan_Status        614 non-null    object \n",
            "dtypes: float64(4), int64(1), object(8)\n",
            "memory usage: 62.5+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select a machine learning model and import it (e.g., RandomForestClassifier from sklearn)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Create an instance of the model\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Train the model using the pre-processed train dataset\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Generate predictions for the pre-processed test dataset\n",
        "y_test_pred = model.predict(X_test_scaled)\n"
      ],
      "metadata": {
        "id": "p6LHcPfJQ7T0"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune the model using techniques like hyperparameter tuning and cross-validation\n",
        "\n",
        "# Example: Perform hyperparameter tuning using GridSearchCV from sklearn\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 5, None],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# Create an instance of GridSearchCV\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
        "\n",
        "# Perform grid search on the pre-processed train dataset\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Get the best model with the tuned hyperparameters\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Generate predictions for the pre-processed test dataset using the best model\n",
        "y_test_pred = best_model.predict(X_test_scaled)\n"
      ],
      "metadata": {
        "id": "gXw7vSHKQmEr"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gF3mHajSI5c",
        "outputId": "7e08b1cc-2056-4478-9231-544214f49450"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'N' 'Y' 'N' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'N' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'N'\n",
            " 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'N' 'N' 'N' 'Y' 'Y' 'N' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'N' 'Y' 'N' 'Y' 'N' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'N' 'Y'\n",
            " 'Y' 'Y' 'N' 'N' 'Y' 'N' 'N' 'N' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'N' 'Y' 'Y'\n",
            " 'Y' 'N' 'N' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'N' 'Y' 'N'\n",
            " 'Y' 'Y' 'Y' 'N' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace the 'Loan_Status' column with the predicted values\n",
        "submission_data = test_data.copy()\n",
        "submission_data['Loan_Status'] = y_test_pred\n",
        "\n",
        "# Save the submission file as a CSV\n",
        "submission_data.to_csv('submission.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "lVvBrszUQsYy",
        "outputId": "326465b7-8132-47d6-c8ba-c672f0d2ce90"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-7d3361b7e19d>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Replace the 'Loan_Status' column with the predicted values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msubmission_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msubmission_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Loan_Status'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Save the submission file as a CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3978\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3979\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3980\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3982\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4172\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4173\u001b[0m         \"\"\"\n\u001b[0;32m-> 4174\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4176\u001b[0m         if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4915\u001b[0;31m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4916\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    569\u001b[0m     \"\"\"\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    572\u001b[0m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Length of values (123) does not match length of index (367)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test_scaled.shape)\n",
        "print(submission_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLH1FWhQRNvG",
        "outputId": "47627ed4-da58-4aa7-ffc5-a3189733e610"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(123, 5)\n",
            "(367, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have already trained and fitted your model\n",
        "\n",
        "# Predict on the test set\n",
        "y_test_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Print the length of y_test_pred and the number of rows in the test dataset\n",
        "print(\"Length of y_test_pred:\", len(y_test_pred))\n",
        "print(\"Number of rows in the test dataset:\", X_test_scaled.shape[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYG166weSgqW",
        "outputId": "12068e08-45a5-4289-8aaf-acd39a17b059"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of y_test_pred: 123\n",
            "Number of rows in the test dataset: 123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have already trained and fitted your model\n",
        "\n",
        "# Predict on the test set\n",
        "y_test_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Print the predicted values\n",
        "print(\"Predicted Loan Approval Status:\")\n",
        "print(y_test_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dhD07zXSpvm",
        "outputId": "01704668-5871-4769-d0e8-63cce6b03507"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Loan Approval Status:\n",
            "['Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'N' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n",
            " 'Y' 'Y' 'Y' 'Y' 'N' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'N'\n",
            " 'Y' 'Y' 'Y' 'N' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'N' 'N' 'N' 'Y' 'Y' 'N' 'Y'\n",
            " 'Y' 'Y' 'Y' 'N' 'N' 'Y' 'N' 'Y' 'N' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'N' 'Y'\n",
            " 'Y' 'Y' 'N' 'N' 'Y' 'N' 'N' 'N' 'N' 'Y' 'Y' 'N' 'Y' 'Y' 'Y' 'N' 'Y' 'Y'\n",
            " 'Y' 'N' 'N' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'N' 'Y' 'N'\n",
            " 'Y' 'Y' 'Y' 'N' 'Y' 'Y' 'N' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have already trained and fitted your model\n",
        "\n",
        "# Predict on the test set\n",
        "y_test_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Create a new DataFrame for submission with the predicted values\n",
        "submission_data = test_data.copy()\n",
        "submission_data['Loan_Status'] = pd.Series(y_test_pred)\n",
        "\n",
        "# Save the submission file as a CSV\n",
        "submission_data.to_csv('submission.csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "dnvqgr1yS6kM"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_data = submission_data[['Loan_ID', 'Loan_Status']]\n"
      ],
      "metadata": {
        "id": "KdpXhJgbTJb9"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_data.to_csv('submission.csv', index=False)\n"
      ],
      "metadata": {
        "id": "smRvMmqEU0JN"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_data['Loan_Status'] = pd.to_numeric(submission_data['Loan_Status'], errors='coerce')\n",
        "\n"
      ],
      "metadata": {
        "id": "TW6WaHLEU3F1"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_data.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "Zxhm1QA4VTz1"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fLTZMzf_VhP1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}